[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "",
    "text": "AI usage disclosure\n\n\n\n\n\nWe used ChatGPT to help write code, clean up code, clarify and streamline text that we wrote, and suggest wording ideas from which we selected specific phrases."
  },
  {
    "objectID": "index.html#purpose",
    "href": "index.html#purpose",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Purpose",
    "text": "Purpose\nWe wondered how protein language models trained on extant sequences would interpret plausible ancestral sequences. To explore this, we used ESM2 to evaluate maximum likelihood ancestral sequence reconstructions for two example gene families. We found that ESM2 often finds these ancestral sequences more plausible than extant descendants, and can distinguish between crude consensus ancestral sequences and more sophisticated maximum likelihood reconstructions. However, these patterns are context- and model-dependent, suggesting that further investigation is needed to determine which evolutionary relationships are truly captured by large protein language models like ESM2.\nWe are sharing these results to encourage further exploration of how large foundation models interpret the evolutionary relationships embedded in their training data. We think this could be useful to researchers interested in interrogating the implicit learning in large protein language models, like ESM2, and we propose that ancestral sequences offer a useful tool for this purpose."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Introduction",
    "text": "Introduction\nProtein language models have emerged as powerful tools for computational biology applications, including fitness prediction, generative protein design, structure prediction, and functional annotation. These models are trained on vast databases of naturally occurring protein sequences with the expectation that they will capture complex relationships underlying these sequences: from fundamental biophysical constraints to evolutionary pressures that have shaped modern proteins (Lin et al. (2023), Hayes et al. (2025), Bhatnagar et al. (2025)). However, the extent to which these models have learned genuine evolutionary principles versus surface-level sequence patterns, and how this varies across model architectures, remains an open question (Lupo et al. (2022), Ektefaie et al. (2025), Tule et al. (2025), York et al. (2025)).\nAncestral sequence reconstruction (ASR) is a potentially useful framework for addressing this question. ASR employs statistical methods to infer the most probable protein sequences of extinct ancestral organisms based on phylogenetic relationships among extant sequences. While these reconstructions may not represent the exact sequences that existed in the past, they reflect evolutionarily plausible intermediates under established models of molecular evolution, and in many cases have been shown to fold and function (Hochberg and Thornton (2017)). This approach offers two key features for probing evolutionary knowledge encoded in protein language models. First, training datasets consist exclusively of extant sequences. Reconstructed ancestral sequences provide opportunities to evaluate the ability of these models to generalize to new sequences. Second, unlike other types of novel sequences, reconstructed ancestral sequences are unique in their evolutionary plausibility. ASR has been successfully applied to reconstruct and experimentally characterize diverse protein families, demonstrating that many reconstructed sequences represent functionally viable proteins (Bridgham et al. (2006), Voordeckers et al. (2012), Wilson et al. (2015)). Thus, ancestral proteins provide an opportunity to assess model confidence in evolutionarily plausible sequences never observed during training and infer the generalizability of evolutionary knowledge contained within pLMs.  \nHere, we focus on the ESM2 protein language model (Lin et al. (2023)), one of the most widely used and well-characterized models to date. ESM2 is trained on millions of extant protein sequences from UniRef and has been applied to a wide range of prediction tasks. It includes multiple model sizes, ranging from 8 million to 15 billion parameters, allowing us to examine how model behavior varies with scale. Using reconstructed ancestral protein sequences from two protein families, we find that ESM2 often assigns higher plausibility to ancestral sequences than to their extant descendants and can distinguish between crude consensus and maximum likelihood reconstructions, particularly for larger ESM2 model sizes. However, we find these relationships to vary significantly across ESM2 model sizes, suggesting the evolutionary learning is inconsistent. This supports the idea that large language models like ESM2 encode evolutionary signal, but indicates that further investigation is needed to determine the extent of this learning."
  },
  {
    "objectID": "index.html#ada1-ancestral-reconstruction",
    "href": "index.html#ada1-ancestral-reconstruction",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "ADA1 ancestral reconstruction",
    "text": "ADA1 ancestral reconstruction\nWe began this analysis with the human protein ADA1, an adenosine deaminase that plays a crucial role in purine metabolism. ADA1 offered several advantages as a test case: it is relatively small (363 amino acids), making computationally intensive pseudo-perplexity calculations more tractable, and is relatively well conserved across taxa, allowing for high-confidence sequence alignments and ancestral reconstructions.\nWe performed ASR on ADA1 by identifying homologs using Protein Cartography (v0.0.2) (Avasthi et al. (2023)), aligning proteins with MAFFT (Katoh et al. (2002)), building a phylogenetic tree with IQTree (Nguyen et al. (2015)), reconstructing maximum likelihood ancestral sequences using PAML (Yang (2007)), and inferring insertions and deletions using PastML (Ishikawa et al. (2019)) (as in Orlandi et al. (2023)).\n\n\n\n\n\n\nNote\n\n\n\nWe performed ancestral reconstructions using a separate notebook, ASR/ASR_notebook.ipynb. This step was conducted separately to keep the main analysis here focused and uncluttered, as ancestral reconstruction involves a multi-stage pipeline with its own set of dependencies and intermediate steps. ASR/README.md provides instructions for reproducing the ancestral sequences used in the present analysis.\n\n\nTo determine the confidence of the ESM2 model in these ancestral sequences, we used pseudo-perplexity as our primary metric (Lin et al. (2023) , Salazar et al. (2020)). Pseudo-perplexity quantifies how well a protein language model can predict each amino acid in a sequence given the surrounding context, essentially measuring the model’s “surprise” at encountering each individual residue. A pseudo-perplexity value near 20 indicates that the model is highly uncertain and assigns roughly equal probability to all 20 amino acids, while a value closer to 1 indicates strong confidence in its prediction. In practice, pseudo-perplexity is computed by summing the negative log-likelihoods of each residue prediction across the entire sequence, yielding a sequence-level score that reflects how grammatically consistent a model believes the sequence to be based on its training on natural proteins. Lower pseudo-perplexity values, therefore, suggest higher plausibility under the model’s learned distribution. By analyzing pseudo-perplexity scores across ancestral sequences with different evolutionary age, we aimed to assess whether protein language models can infer the plausibility of ancestrally reconstructed sequences and how their confidence varies across evolutionary time."
  },
  {
    "objectID": "index.html#ada1-phylogeny",
    "href": "index.html#ada1-phylogeny",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "ADA1 phylogeny",
    "text": "ADA1 phylogeny\nWe first wanted to assess how ESM2 pseudo-perplexity varies between ancestral and native sequences and the effect of ancestral age. To start, we looked at the human ADA1 protein P00813.\n\n\nCode\nimport arcadia_pycolor as apc\n\nfrom src.analysis.data_processing import plot_image_with_arrow_and_circles, plot_image_with_arrows\n\napc.mpl.setup()\n\nimg_path = \"images/ADA1_tree.png\"\nplot_image_with_arrows(\n    img_path,\n    x_starts=[0.73],\n    x_ends=[0.60],\n    arrow_ys=[0.045],\n    labels=[\"P00813_Homo_sapiens\"],\n    text_offsets=[0.01],\n)\n\n\n\n\n\n\n\n\nFigure 1: Phylogenetic tree of ADA1 homologs with location of human ADA1 indicated by arrow.\n\n\n\n\n\nWe determined every ancestral node leading to this extant leaf and its maximum likelihood ancestral sequence, as shown in the example below.\n\n\nCode\nnode_img_path = \"images/tree_nodes_example.png\"\nplot_image_with_arrow_and_circles(\n    img_path=node_img_path,\n    x_start=0.97,\n    x_end=0.89,\n    arrow_y=0.01,\n    circle_positions=[\n        (0.771, 0.025),\n        (0.70, 0.058),\n        (0.675, 0.105),\n        (0.604, 0.155),\n        (0.553, 0.197),\n        (0.48, 0.23),\n        (0.335, 0.27),\n        (0.285, 0.335),\n        (0.178, 0.41),\n        (0.146, 0.515),\n        (0.066, 0.625),\n    ],\n    circle_radius=6,\n)\n\n\n\n\n\n\n\n\nFigure 2: Example of all ancestral nodes (orange circles) on the lineage of an example leaf of interest (orange arrow). The basal node of the tree was not included, as our ASR pipeline does not reconstruct this node."
  },
  {
    "objectID": "index.html#loading-the-data",
    "href": "index.html#loading-the-data",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Loading the data",
    "text": "Loading the data\nWe calculated pseudo-perplexity scores using the 650M ESM2 model for relevant ancestral sequences and extant sequences in our dataset to begin inferring model confidence of reconstructed sequences.\n\n\n\n\n\n\nNote\n\n\n\nWe performed pseudo-perplexity calculations using the script ESM2_scoring/esm2_pppl_calculator.py. This step was conducted separately because it required GPU compute for efficient execution. ESM2_scoring/README.md provides instructions for reproducing the perplexity scores used in the present analysis.\n\n\nIn addition to pseudo-perplexity values, we extracted the mean posterior probabilities for each ancestral reconstruction from the PAML output. Posterior probability in this context represents the statistical confidence of the maximum likelihood reconstruction.  Specifically, it quantifies the probability that each amino acid at each position in the ancestral sequence is correctly inferred given the appropriate phylogenetic model and observed extant sequences. Higher values, close to 1.0, indicate high confidence in the protein reconstruction.\nTo quantify evolutionary divergence, we calculated the total branch length from the root to each ancestral node and extant leaf in our phylogenetic tree. This allowed us to examine how ESM2 confidence varies across evolutionary age.\n\nimport json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom Bio import Phylo\n\nesm2_dir = Path(\"ESM2_scoring/outputs/\")\n\n# Import ADA1 sequences scored for ESM2 pppl\nall_scores = pd.read_csv(esm2_dir / \"ADA1_all_esm2_scores_650M.csv\")\nall_scores = all_scores[[\"sequence_id\", \"sequence\", \"pseudo_perplexity\"]]\n\n# Retrieve ML posterior probabilities from ASR run\nml_probs_json = Path(\"ASR/ADA1_ASR/outputs/posterior_probabilities_no_gaps.json\")\nwith open(ml_probs_json) as f:\n    probs_dict = json.load(f)\n\n# Add posterior probabilities to dataframe\nall_scores[\"ML prob\"] = all_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict[x]]) if x in probs_dict else np.nan\n)\n\n# Import phylogenetic tree to infer ancestors of leaf of interest\ntree_file = \"ASR/ADA1_ASR/outputs/ancestor_tree.txt\"\ntree = Phylo.read(tree_file, \"newick\")\n\n# Calculate the branch length to the root for every ancestor and native sequence\nfrom src.analysis.data_processing import (\n    calc_branch_length_to_root_leaf,\n    calc_branch_length_to_root_node,\n)\n\nall_scores[\"bl_to_root\"] = all_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(tree, x)\n)"
  },
  {
    "objectID": "index.html#visualizing-esm2-pseudo-perplexity-vs.-evolutionary-distance",
    "href": "index.html#visualizing-esm2-pseudo-perplexity-vs.-evolutionary-distance",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Visualizing ESM2 pseudo-perplexity vs. evolutionary distance",
    "text": "Visualizing ESM2 pseudo-perplexity vs. evolutionary distance\nPlotting ESM2 pseudo-perplexity scores against evolutionary distance from the tree root allows us to examine the effect of both ancestral age (distance to tree root) and reconstruction confidence (posterior probability) on the pseudo-perplexity score.\n\nfrom src.analysis.data_processing import get_node_labels_leaf_to_root, plot_evo_path\n\nplot_evo_path(all_scores, tree, \"P00813_Homo_sapiens\")\n\n\n\n\n\n\n\nFigure 3: ESM2 pseudo-perplexity scores for ADA1 sequences, colored by ML posterior probability bin. The x-axis shows the branch length to the root node of the tree, with the extant sequence on the far right (orange). The y-axis shows ESM2 pseudo-perplexity score.\n\n\n\n\n\nESM2 assigns lower pseudo-perplexity scores to recent ancestral sequences compared to the extant human sequence, suggesting that the model considers these reconstructed ancestors more plausible than the native sequence. This is intriguing given that these ancestral sequences were never present in the training data, and may indicate that ESM2 has inferred specific evolutionary patterns sufficiently to recognize some high-confidence ancestral reconstructions as sound.\nHowever, as evolutionary distance increases, pseudo-perplexity scores rise and eventually surpass the native score. This suggests the model finds these basal ancestors less plausible than the native and more recent ancestral sequences. \nWe wondered how general this phenomenon was, so we examined three additional extant leaves in our ADA1 phylogenetic tree and ancestral nodes on their respective lineages.\n\n\nCode\nplot_image_with_arrows(\n    img_path,\n    x_starts=[0.73, 0.89, 0.86, 0.78],\n    x_ends=[0.60, 0.76, 0.73, 0.65],\n    arrow_ys=[0.045, 0.44, 0.305, 0.745],\n    labels=[\n        \"P00813_Homo_sapiens\",\n        \"A0A8S4BYQ7_Menidia_menidia\",\n        \"A0A673JME8_Sinocyclocheilus_rhinocerous\",\n        \"A0A8J6K0P8_Eleutherodactylus_coqui\",\n    ],\n    text_offsets=[0.01, 0.01, 0.01, 0.01],\n)\n\n\n\n\n\n\n\n\nFigure 4: Phylogenetic tree of ADA1 with additional extant leaf positions indicated by arrows.\n\n\n\n\n\n\nplot_evo_path(all_scores, tree, \"A0A673JME8_Sinocyclocheilus_rhinocerous\")\nplot_evo_path(all_scores, tree, \"A0A8S4BYQ7_Menidia_menidia\")\nplot_evo_path(all_scores, tree, \"A0A8J6K0P8_Eleutherodactylus_coqui\")\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\nFigure 5: ESM2 pseudo-perplexity vs distance to tree root for three additional species lineages.\n\n\n\n\nHere we see a similar pattern: recent ancestors show lower pseudo-perplexity scores than their native descendants, but these scores increase for the oldest ancestors. Unlike human ADA1, however, none of these other ancestors showed higher pseudo-perplexity scores than their native sequences, suggesting this isn’t universal. This may reflect the lower baseline score of human ADA1 compared to the others, perhaps due to over-representation of human and closely related sequences in the training set compared to these other species. However, we consistently observe that ESM2 considers many ancestral sequences more plausible than native sequences across different species."
  },
  {
    "objectID": "index.html#assessing-the-role-of-consensus-effects",
    "href": "index.html#assessing-the-role-of-consensus-effects",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Assessing the role of consensus effects",
    "text": "Assessing the role of consensus effects\nWe wondered whether ESM’s general preference for ancestral sequences reflects primarily a consensus effect in these models. Maximum likelihood ancestral reconstructions, while statistically based, often favor amino acids that are common among descendant sequences, potentially creating sequences that align with the frequency distributions in the ESM2 training data. Therefore, ESM2 might prefer these sequences simply because they contain high-frequency amino acids.\nTo test this hypothesis, we generated “consensus ancestors” as controls. For each ancestral node, we identified all extant sequences descending from that node. We constructed a consensus sequence by choosing the most frequent amino acid found at each position in the alignment. This relatively simple approach differs fundamentally from maximum likelihood reconstruction, which incorporates evolutionary models, branch lengths, and substitution matrices to infer the most probable ancestral state given the entire phylogenetic context.\n\nfrom Bio.Seq import Seq\nfrom Bio.SeqRecord import SeqRecord\n\nfrom src.analysis.data_processing import generate_node_consensus, get_node_labels_leaf_to_root\n\nleaves_of_interest = [\n    \"P00813_Homo_sapiens\",\n    \"A0A8S4BYQ7_Menidia_menidia\",\n    \"A0A673JME8_Sinocyclocheilus_rhinocerous\",\n    \"A0A8J6K0P8_Eleutherodactylus_coqui\",\n]\nancestors_of_interest = []\n\nfor entry in leaves_of_interest:\n    ancestors_of_interest.extend(get_node_labels_leaf_to_root(tree, entry))\n\nancestors_of_interest = list(set(ancestors_of_interest))\n\nalignment_file = \"ASR/ADA1_ASR/outputs/ADA1_curated_022525_under420_recoded_mafft.fa\"\nname_conv_dict = \"ASR/ADA1_ASR/outputs/recoding_dict.txt\"\ngap_dict_json = \"ASR/ADA1_ASR/outputs/gap_positions.json\"\n\nconsensus_seq_file = esm2_dir.parent / \"inputs\" / \"consensus_ADA1_ancestors.fa\"\n\nrecords = []\nfor entry in ancestors_of_interest:\n    consensus_seq = generate_node_consensus(\n        tree, entry, alignment_file, name_conv_dict, gap_dict_json\n    )\n    name = entry + \"_consensus\"\n    record = SeqRecord(Seq(consensus_seq), id=name, description=\"\")\n    records.append(record)\n\nWe then calculated pseudo-perplexity scores for these consensus ancestors using the ESM2 650M-parameter model.\n\n# retrieve esm2 scores for consensus seqs\nconsensus_file = esm2_dir / \"consensus_ADA1_ancestors_esm2_scores_650M.csv\"\nconsensus_scores = pd.read_csv(consensus_file)\nconsensus_scores[\"orig_id\"] = consensus_scores[\"sequence_id\"].apply(\n    lambda x: x.replace(\"_consensus\", \"\")\n)\nconsensus_scores = consensus_scores[[\"orig_id\", \"sequence\", \"pseudo_perplexity\"]]\nconsensus_scores = consensus_scores.rename(\n    columns={\n        \"sequence\": \"consensus_seq\",\n        \"pseudo_perplexity\": \"consensus_pppl\",\n        \"orig_id\": \"sequence_id\",\n    }\n)\n\n\n# add new consensus seqs and scores to scores df\nall_scores = all_scores.merge(consensus_scores, how=\"left\", on=\"sequence_id\")\n\nBelow, we compared the ESM2 pseudo-perplexity scores of these consensus ancestors to the scores of genuine maximum likelihood ancestors for the four extant sequences we previously examined. \n\nfrom src.analysis.data_processing import plot_evo_path_quiver\n\nplot_evo_path_quiver(all_scores, tree, \"P00813_Homo_sapiens\", \"upper right\")\nplot_evo_path_quiver(all_scores, tree, \"A0A8S4BYQ7_Menidia_menidia\")\nplot_evo_path_quiver(all_scores, tree, \"A0A673JME8_Sinocyclocheilus_rhinocerous\")\nplot_evo_path_quiver(all_scores, tree, \"A0A8J6K0P8_Eleutherodactylus_coqui\")\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\nFigure 6: ESM2 pseudo-perplexity (pppl) scores for consensus and maximum likelihood (ML) ancestors of ADA1, with arrows indicating which ancestor has the lower pseudo-perplexity score.\n\n\n\n\nMaximum likelihood ancestors frequently show lower pseudo-perplexity scores than their corresponding consensus ancestors. However, both types of ancestral sequences often scored lower than extant sequences, indicating that a consensus effect partially drives the observed preference for ancestral sequences.\nHowever, the relationship between maximum likelihood and consensus ancestors varies with evolutionary distance. For recent ancestors, maximum likelihood sequences consistently outperform consensus ancestors, suggesting that ESM2 has learned to recognize evolutionarily informed reconstructions as more plausible than simple frequency-based sequences. This indicates that the model has internalized aspects of evolutionary relationships beyond mere amino acid frequency distributions. However, this relationship reverses for more ancient ancestors, where consensus sequences often achieve lower pseudo-perplexity scores than maximum likelihood reconstructions. These ancient reconstructions also exhibit lower posterior probabilities, so this reversal may reflect increased uncertainty and potential errors in the maximum likelihood reconstructions. Alternatively, this behavior could reflect over-fitting to native sequences, given that consensus sequences likely more closely match the frequency distributions of the training set. While it’s difficult to distinguish between these two factors for the oldest ancestors, for more recent ancestors it’s clear that ESM2 can infer that maximum likelihood ancestors are significantly more plausible than crude consensus ancestors."
  },
  {
    "objectID": "index.html#comparing-different-esm2-model-sizes",
    "href": "index.html#comparing-different-esm2-model-sizes",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Comparing different ESM2 model sizes",
    "text": "Comparing different ESM2 model sizes\nWe were curious to know how much of the evolutionary information ESM2 seems to be learning is consistent across different model sizes or whether this information is only captured in large models. To investigate this, we repeated the above analysis with different ESM2 model sizes: 8M, 35M, 150M, and 3B parameters (in addition to the previously shown 650M). \n\nsmall_model_scores = pd.read_csv(esm2_dir / \"ADA1_all_esm2_scores_8M.csv\")\nmed_model_scores = pd.read_csv(esm2_dir / \"ADA1_all_esm2_scores_35M.csv\")\nlarge_model_scores = pd.read_csv(esm2_dir / \"ADA1_all_esm2_scores_150M.csv\")\nhuge_model_scores = pd.read_csv(esm2_dir / \"ADA1_all_esm2_scores_3B.csv\")\n\nsmall_model_scores[\"ML prob\"] = small_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict[x]]) if x in probs_dict else np.nan\n)\nsmall_model_scores[\"bl_to_root\"] = small_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(tree, x)\n)\n\nmed_model_scores[\"ML prob\"] = med_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict[x]]) if x in probs_dict else np.nan\n)\nmed_model_scores[\"bl_to_root\"] = med_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(tree, x)\n)\n\nlarge_model_scores[\"ML prob\"] = large_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict[x]]) if x in probs_dict else np.nan\n)\nlarge_model_scores[\"bl_to_root\"] = large_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(tree, x)\n)\n\nhuge_model_scores[\"ML prob\"] = huge_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict[x]]) if x in probs_dict else np.nan\n)\nhuge_model_scores[\"bl_to_root\"] = huge_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(tree, x)\n)\n\nWe can then plot the same relationship between ESM2 pseudo-perplexity and distance to tree root for these different model sizes to see if they exhibit similar behavior.\n\nfrom src.analysis.data_processing import plot_multiple_evo_lines\n\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"P00813_Homo_sapiens\", \"8M\"),\n        (med_model_scores, \"P00813_Homo_sapiens\", \"35M\"),\n        (large_model_scores, \"P00813_Homo_sapiens\", \"150M\"),\n        (all_scores, \"P00813_Homo_sapiens\", \"650M\"),\n        (huge_model_scores, \"P00813_Homo_sapiens\", \"3B\"),\n    ],\n    tree,\n    normalize=False,\n)\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"8M\"),\n        (med_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"35M\"),\n        (large_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"150M\"),\n        (all_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"650M\"),\n        (huge_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"3B\"),\n    ],\n    tree,\n    normalize=False,\n)\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"8M\"),\n        (med_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"35M\"),\n        (large_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"150M\"),\n        (all_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"650M\"),\n        (huge_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"3B\"),\n    ],\n    tree,\n    normalize=False,\n)\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"8M\"),\n        (med_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"35M\"),\n        (large_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"150M\"),\n        (all_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"650M\"),\n        (huge_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"3B\"),\n    ],\n    tree,\n    normalize=False,\n)\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\nFigure 7: ESM2 pseudo-perplexity vs distance to tree root for five different ESM2 model sizes for four species lineages.\n\n\n\n\nLarger models consistently produce overall lower pseudo-perplexity scores, reflecting their improved ability to learn protein sequence patterns. However, the relationship between pseudo-perplexity and evolutionary age varies across model sizes. To facilitate easier comparison across models, we normalized all pseudo-perplexity values to each model’s extant sequence pseudo-perplexity score.\n\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"P00813_Homo_sapiens\", \"8M\"),\n        (med_model_scores, \"P00813_Homo_sapiens\", \"35M\"),\n        (large_model_scores, \"P00813_Homo_sapiens\", \"150M\"),\n        (all_scores, \"P00813_Homo_sapiens\", \"650M\"),\n        (huge_model_scores, \"P00813_Homo_sapiens\", \"3B\"),\n    ],\n    tree,\n)\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"8M\"),\n        (med_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"35M\"),\n        (large_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"150M\"),\n        (all_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"650M\"),\n        (huge_model_scores, \"A0A8S4BYQ7_Menidia_menidia\", \"3B\"),\n    ],\n    tree,\n)\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"8M\"),\n        (med_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"35M\"),\n        (large_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"150M\"),\n        (all_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"650M\"),\n        (huge_model_scores, \"A0A673JME8_Sinocyclocheilus_rhinocerous\", \"3B\"),\n    ],\n    tree,\n)\nplot_multiple_evo_lines(\n    [\n        (small_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"8M\"),\n        (med_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"35M\"),\n        (large_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"150M\"),\n        (all_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"650M\"),\n        (huge_model_scores, \"A0A8J6K0P8_Eleutherodactylus_coqui\", \"3B\"),\n    ],\n    tree,\n)\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\nFigure 8: Normalized ESM2 pseudo-perplexity vs distance to tree root for different ESM2 model sizes. For each species lineage, the pseudo-perplexity scores for each model are normalized to the score for the extant sequence for that model size.\n\n\n\n\nThis normalization reveals distinct differences in how models of varying sizes score ancestors of different ages. The larger models (650M and 3B parameters) show dramatic increases in pseudo-perplexity for the oldest ancestors compared to recent ancestors or extant sequences, while the smallest models show only gradual increases for these ancient sequences. Conversely, the largest models demonstrate the most significant decreases in pseudo-perplexity for the most recent ancestors relative to extant sequences.\nThese patterns suggest the models learn evolutionary principles to markedly different extents. The largest models disfavor low-confidence reconstructions while favoring high-confidence reconstructions. This could reflect genuine evolutionary learning or overfitting to native-like sequences. Meanwhile, the smallest models show minimal pseudo-perplexity differences from native to deepest ancestors, though their absolute scores remain relatively high (&gt; 10) compared to the much lower scores (&lt; 3) of larger models.\nMost importantly, these results demonstrate that ESM2 model size is critically essential for evolutionary analysis. Depending on which model size you use for this analysis, you could reach vastly different conclusions: that all ancestors are more plausible than native sequences, that some ancestors are more plausible, that ancestors and native sequences are similarly plausible, or that ancestral age strongly affects plausibility."
  },
  {
    "objectID": "index.html#second-example-gene-yeast-isomaltase",
    "href": "index.html#second-example-gene-yeast-isomaltase",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Second example gene: Yeast isomaltase",
    "text": "Second example gene: Yeast isomaltase\nWe examined yeast isomaltase to explore whether these findings generalized to other proteins. Isomaltase produced high-quality alignments and phylogenetic trees, was relatively small for pseudo-perplexity calculations (589 amino acids), and showed a phylogenetic structure similar to ADA1. Ancestral reconstructions displayed high confidence toward terminal leaves and lower (but still reasonable) confidence at basal nodes. While not all gene phylogenies follow this pattern, we wanted to understand how ESM2 behaves with this fairly typical phylogenetic structure. Future work could expand this analysis to genes with more diverse phylogenetic patterns to examine how pseudo-perplexity varies across different tree topologies.\nWe selected three extant leaves to interrogate in the same manner as above, their location on the isomaltase phylogenetic tree is shown below.\n\nimg_path = \"images/isomaltase_tree.png\"\nplot_image_with_arrows(\n    img_path,\n    x_starts=[0.94, 0.96, 0.88],\n    x_ends=[0.81, 0.83, 0.75],\n    arrow_ys=[0.105, 0.343, 0.56],\n    labels=[\n        \"A0A420MWB1_Fusarium_oxysporum\",\n        \"A0A177DQL5_Alternaria_alternata\",\n        \"A0A4T0C5S8_Aureobasidium_pullulans\",\n    ],\n    text_offsets=[0.01, 0.01, 0.01],\n)\n\n\n\n\n\n\n\nFigure 9: Phylogenetic tree of isomaltase with extant leaf positions indicated by arrows.\n\n\n\n\n\nIt’s worth noting that the scale of substitutions per site is much smaller for isomaltase than ADA1, indicating that these sequences are less divergent (maximum branch length ~1.5 vs. ~2.5 for ADA1). Correspondingly, the overall ASR mean posterior probabilities are also higher.\nWe can then plot the ESM2 pseudo-perplexity (650M-parameter model) compared to the distance to tree root as we did for ADA1 for all three leaves.\n\n# get ESM2 scores for isomaltase\niso_scores = pd.read_csv(esm2_dir / \"isomaltase_all_esm2_scores_650M.csv\")\n\n# retrieve the dictionary of probabilities from PAML output\nml_probs_json = \"ASR/Isomaltase_ASR/outputs/posterior_probabilities_no_gaps.json\"\nml_probs_json = Path(ml_probs_json)\nwith open(ml_probs_json) as f:\n    iso_probs_dict = json.load(f)\n\niso_scores[\"ML prob\"] = iso_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in iso_probs_dict[x]]) if x in iso_probs_dict else np.nan\n)\n\ntree_file = \"ASR/Isomaltase_ASR/outputs/ancestor_tree.txt\"\niso_tree = Phylo.read(tree_file, \"newick\")\n\niso_scores[\"bl_to_root\"] = iso_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(iso_tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(iso_tree, x)\n)\n\n\nplot_evo_path(iso_scores, iso_tree, \"A0A420MWB1_Fusarium_oxysporum\", labels=False)\nplot_evo_path(iso_scores, iso_tree, \"A0A177DQL5_Alternaria_alternata\", labels=False)\nplot_evo_path(iso_scores, iso_tree, \"A0A4T0C5S8_Aureobasidium_pullulans\", labels=False)\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\nFigure 10: ESM2 pseudo-perplexity scores for isomaltase sequences, colored by ML posterior probability bin. The x-axis shows the branch length to the root node of the tree, with the extant sequence on the far right (orange). The y-axis shows ESM2 pseudo-perplexity score.\n\n\n\n\nIsomaltase reveals similar but attenuated patterns compared to ADA1: pseudo-perplexity decreases among recent ancestors relative to extant sequences, though less pronounced than ADA1. This is followed by leveling off and slight increases for the oldest ancestors, again much less dramatic than the ADA1 pattern. These results confirm that ESM2’s preference for ancestral sequences over native sequences extends to this second gene family. However, we don’t observe the sharp increase in pseudo-perplexity seen with ADA1’s most ancient ancestors, likely because isomaltase lacks reconstructions with comparably low posterior probabilities or similar branch length divergence.\nWe also generated consensus ancestral sequences for isomaltase and compared their ESM2 pseudo-perplexity scores to maximum likelihood ancestral sequences.\n\n# generate isomaltase consensus ancestors\n\nleaves_of_interest = [\n    \"A0A420MWB1_Fusarium_oxysporum\",\n    \"A0A177DQL5_Alternaria_alternata\",\n    \"A0A4T0C5S8_Aureobasidium_pullulans\",\n]\nancestors_of_interest = []\n\nfor entry in leaves_of_interest:\n    ancestors_of_interest.extend(get_node_labels_leaf_to_root(iso_tree, entry))\n\nancestors_of_interest = list(set(ancestors_of_interest))\n\nalignment_file = \"ASR/Isomaltase_ASR/outputs/isomaltase_dereplicated_final_recoded_mafft.fa\"\nname_conv_dict = \"ASR/Isomaltase_ASR/outputs/recoding_dict.txt\"\ngap_dict_json = \"ASR/Isomaltase_ASR/outputs/gap_positions.json\"\n\nconsensus_seq_file = \"consensus_isomaltase_ancestors.fa\"\n\nrecords = []\nfor entry in ancestors_of_interest:\n    consensus_seq = generate_node_consensus(\n        iso_tree, entry, alignment_file, name_conv_dict, gap_dict_json\n    )\n    name = entry + \"_consensus\"\n    record = SeqRecord(Seq(consensus_seq), id=name, description=\"\")\n    records.append(record)\n\n\n# retrieve esm2 scores for consensus seqs\nconsensus_file = esm2_dir / \"consensus_isomaltase_ancestors_esm2_scores_650M.csv\"\nconsensus_scores = pd.read_csv(consensus_file)\nconsensus_scores[\"orig_id\"] = consensus_scores[\"sequence_id\"].apply(\n    lambda x: x.replace(\"_consensus\", \"\")\n)\nconsensus_scores = consensus_scores[[\"orig_id\", \"sequence\", \"pseudo_perplexity\"]]\nconsensus_scores = consensus_scores.rename(\n    columns={\n        \"sequence\": \"consensus_seq\",\n        \"pseudo_perplexity\": \"consensus_pppl\",\n        \"orig_id\": \"sequence_id\",\n    }\n)\n\n# add new consensus seqs and scores to scores df\niso_scores = iso_scores.merge(consensus_scores, how=\"left\", on=\"sequence_id\")\n\n\nplot_evo_path_quiver(iso_scores, iso_tree, \"A0A420MWB1_Fusarium_oxysporum\", \"lower right\")\nplot_evo_path_quiver(iso_scores, iso_tree, \"A0A177DQL5_Alternaria_alternata\")\nplot_evo_path_quiver(iso_scores, iso_tree, \"A0A4T0C5S8_Aureobasidium_pullulans\")\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\nFigure 11: ESM2 pseudo-perplexity (pppl) scores for consensus and maximum likelihood (ML) ancestors of ADA1, with arrows indicating which ancestor has the lower pseudo-perplexity score.\n\n\n\n\nThis comparison shows distinct behavior from ADA1. In virtually all cases, pseudo-perplexity scores for maximum likelihood ancestors were lower than those for consensus ancestors. Overall, the model greatly prefers maximum likelihood ancestors for isomaltase, suggesting that the phylogenetic signal has been largely learned by the model rather than simple amino acid frequency distributions.\nWe also tested these sequences using different-sized ESM2 models to see if we observe differences between model sizes, as with ADA1. Below are the normalized scores.\n\n# load esm2 scores for isomaltase\n\niso_small_model_scores = pd.read_csv(esm2_dir / \"isomaltase_all_esm2_scores_8M.csv\")\niso_med_model_scores = pd.read_csv(esm2_dir / \"isomaltase_all_esm2_scores_35M.csv\")\niso_large_model_scores = pd.read_csv(esm2_dir / \"isomaltase_all_esm2_scores_150M.csv\")\niso_huge_model_scores = pd.read_csv(esm2_dir / \"isomaltase_all_esm2_scores_3B.csv\")\n\niso_small_model_scores[\"ML prob\"] = iso_small_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in iso_probs_dict[x]]) if x in iso_probs_dict else np.nan\n)\niso_small_model_scores[\"bl_to_root\"] = iso_small_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(iso_tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(iso_tree, x)\n)\n\niso_med_model_scores[\"ML prob\"] = iso_med_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in iso_probs_dict[x]]) if x in iso_probs_dict else np.nan\n)\niso_med_model_scores[\"bl_to_root\"] = iso_med_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(iso_tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(iso_tree, x)\n)\n\niso_large_model_scores[\"ML prob\"] = iso_large_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in iso_probs_dict[x]]) if x in iso_probs_dict else np.nan\n)\niso_large_model_scores[\"bl_to_root\"] = iso_large_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(iso_tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(iso_tree, x)\n)\n\niso_huge_model_scores[\"ML prob\"] = iso_huge_model_scores[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in iso_probs_dict[x]]) if x in iso_probs_dict else np.nan\n)\niso_huge_model_scores[\"bl_to_root\"] = iso_huge_model_scores[\"sequence_id\"].apply(\n    lambda x: calc_branch_length_to_root_node(iso_tree, x[4:])\n    if x.startswith(\"node\")\n    else calc_branch_length_to_root_leaf(iso_tree, x)\n)\n\n\nplot_multiple_evo_lines(\n    [\n        (iso_small_model_scores, \"A0A420MWB1_Fusarium_oxysporum\", \"8M\"),\n        (iso_med_model_scores, \"A0A420MWB1_Fusarium_oxysporum\", \"35M\"),\n        (iso_large_model_scores, \"A0A420MWB1_Fusarium_oxysporum\", \"150M\"),\n        (iso_scores, \"A0A420MWB1_Fusarium_oxysporum\", \"650M\"),\n        (iso_huge_model_scores, \"A0A420MWB1_Fusarium_oxysporum\", \"3B\"),\n    ],\n    iso_tree,\n    normalize=True,\n)\nplot_multiple_evo_lines(\n    [\n        (iso_small_model_scores, \"A0A177DQL5_Alternaria_alternata\", \"8M\"),\n        (iso_med_model_scores, \"A0A177DQL5_Alternaria_alternata\", \"35M\"),\n        (iso_large_model_scores, \"A0A177DQL5_Alternaria_alternata\", \"150M\"),\n        (iso_scores, \"A0A177DQL5_Alternaria_alternata\", \"650M\"),\n        (iso_huge_model_scores, \"A0A177DQL5_Alternaria_alternata\", \"3B\"),\n    ],\n    iso_tree,\n    normalize=True,\n)\nplot_multiple_evo_lines(\n    [\n        (iso_small_model_scores, \"A0A4T0C5S8_Aureobasidium_pullulans\", \"8M\"),\n        (iso_med_model_scores, \"A0A4T0C5S8_Aureobasidium_pullulans\", \"35M\"),\n        (iso_large_model_scores, \"A0A4T0C5S8_Aureobasidium_pullulans\", \"150M\"),\n        (iso_scores, \"A0A4T0C5S8_Aureobasidium_pullulans\", \"650M\"),\n        (iso_huge_model_scores, \"A0A4T0C5S8_Aureobasidium_pullulans\", \"3B\"),\n    ],\n    iso_tree,\n    normalize=True,\n)\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\nFigure 12: Normalized ESM2 pseudo-perplexity vs distance to tree root for different ESM2 model sizes. For each species lineage, the pseudo-perplexity scores for each model are normalized to the score for the extant sequence for that model size.\n\n\n\n\nHere, we observe a similar phenomenon where the smallest models showed largely consistent pseudo-perplexity scores. In contrast, the largest models showed more pronounced increases in pseudo-perplexity than the oldest ancestors. This pattern was consistent with ADA1 observations but less dramatic. Nonetheless, this observation is consistent with the idea that selection of ESM2 model size is essential in interpreting the plausibility of ancestral sequences relative to native."
  },
  {
    "objectID": "index.html#relationship-between-asr-confidence-and-esm2-pseudo-perplexity",
    "href": "index.html#relationship-between-asr-confidence-and-esm2-pseudo-perplexity",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Relationship between ASR confidence and ESM2 pseudo-perplexity",
    "text": "Relationship between ASR confidence and ESM2 pseudo-perplexity\nThe isomaltase results prompted us to investigate whether a general relationship exists between maximum likelihood ancestral reconstruction posterior probabilities and ESM2 pseudo-perplexity. We pooled results from both ADA1 and isomaltase phylogenies and calculated pseudo-perplexity scores for all native and ancestral sequences using the 650M-parameter model.\n\n# pull data for all remaining ADA1 sequences\nremaining_df = pd.read_csv(esm2_dir / \"ADA1_remaining_esm2_scores_650M.csv\")\nremaining_df = remaining_df[[\"sequence_id\", \"sequence\", \"pseudo_perplexity\"]]\n\n# combine with original scores\nall_scores = pd.read_csv(esm2_dir / \"ADA1_all_esm2_scores_650M.csv\")\nall_scores = all_scores[[\"sequence_id\", \"sequence\", \"pseudo_perplexity\"]]\nfull_data = pd.concat([remaining_df, all_scores])\n\n# Add in ML posterior probabilities from ASR run\nml_probs_json = \"ASR/ADA1_ASR/outputs/posterior_probabilities_no_gaps.json\"\nml_probs_json = Path(ml_probs_json)\nwith open(ml_probs_json) as f:\n    probs_dict = json.load(f)\nfull_data[\"ML prob\"] = full_data[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict[x]]) if x in probs_dict else np.nan\n)\nfull_data[\"ML prob\"] = full_data[\"ML prob\"].fillna(1.1)\n\n# pull data for all iso native and ancestor\nremaining_df = pd.read_csv(esm2_dir / \"isomaltase_remaining_esm2_scores_650M.csv\")\nremaining_df = remaining_df[[\"sequence_id\", \"sequence\", \"pseudo_perplexity\"]]\n\n# combine with original scores\niso_scores = pd.read_csv(esm2_dir / \"isomaltase_all_esm2_scores_650M.csv\")\niso_scores = iso_scores[[\"sequence_id\", \"sequence\", \"pseudo_perplexity\"]]\nfull_data_iso = pd.concat([remaining_df, iso_scores])\n\n# Retrieve ML posterior probabilities from ASR run\nml_probs_json = \"ASR/Isomaltase_ASR/outputs/posterior_probabilities_no_gaps.json\"\nml_probs_json = Path(ml_probs_json)\nwith open(ml_probs_json) as f:\n    probs_dict_iso = json.load(f)\nfull_data_iso[\"ML prob\"] = full_data_iso[\"sequence_id\"].apply(\n    lambda x: np.mean([max(x) for x in probs_dict_iso[x]]) if x in probs_dict_iso else np.nan\n)\nfull_data_iso[\"ML prob\"] = full_data_iso[\"ML prob\"].fillna(1.1)\n\n# merge all data together\nfull_data_both = pd.concat([full_data, full_data_iso])\nfull_data_both = full_data_both.drop_duplicates()\n\n# print sizes of each\nprint(f\"Total ADA1 sequences: {len(full_data)}\")\nprint(f\"Total Isomaltase sequences: {len(full_data_iso)}\")\n\nTotal ADA1 sequences: 461\nTotal Isomaltase sequences: 571\n\n\nWe can then view the relationship between ML posterior probability and ESM2 pseudo-perplexity for all these sequences.\n\n\nCode\nfrom src.analysis.data_processing import violin_plot\n\nbins = [0.7, 0.8, 0.85, 0.9, 0.95, 1.0, 1.1]\nbin_labels = [\"&lt; 0.8\", \"0.80-0.85\", \"0.85-0.90\", \"0.90-0.95\", \"0.95-1.00\", \"Extant\"]\n\nviolin_plot(full_data_both, bins, bin_labels)\n\n\n\n\n\n\n\n\nFigure 13: Violin plot of ESM2 pseudo-perplexity scores for both ADA1 and isomaltase sequences, binned by ML posterior probability. Horizontal bar indicates median score in each bin and number of samples in each bin indicated above.\n\n\n\n\n\nHere we do observe a broad pattern. We see the highest median pseudo-perplexity for extant sequences. Values decrease in the 0.95-1.0 and 0.90-0.95 posterior probability bins, level off in the 0.85-0.9 bins, and begin increasing again as probabilities drop below 0.85.\nTo test the significance of these differences, we performed a Kruskal–Wallis and Dunn-Bonferroni post-hoc test.\n\nfrom src.analysis.data_processing import kruskal_wallis_with_significant_posthoc\n\n# Perform Kruskal-Wallis test and Dunn-Benforroni and print significant comparisons\nkruskal_wallis_with_significant_posthoc(full_data_both, bins, bin_labels)\n\nKruskal-Wallis test result: H = 191.825, p = 1.591e-39\n\nSignificant Dunn post hoc comparisons (adjusted p &lt; 0.05):\nGroup 1      Group 2      Adj. p-value\n--------------------------------------\n&lt; 0.8        0.85-0.90    4.420e-04   \n&lt; 0.8        0.90-0.95    5.322e-06   \n&lt; 0.8        0.95-1.00    4.800e-04   \n0.85-0.90    Extant       4.610e-06   \n0.90-0.95    Extant       5.500e-14   \n0.95-1.00    Extant       3.694e-31   \n\n\nThese analyses indicate a significant effect of ML posterior probability bin on pseudo-perplexity (p &lt;&lt; 0.001). Post hoc tests revealed that both extant sequences and the lowest-confidence ancestral reconstructions (&lt; 0.8) exhibit significantly higher pseudo-perplexity than the high-confidence reconstructed bins. Differences among the intermediate confidence bins themselves weren’t statistically significant.\nWhile broader generalization will require analyzing more genes, these results support the idea that ancestral sequences tend to show lower pseudo-perplexity than extant sequences, up to a point. Once mean posterior probabilities drop below ~0.85, pseudo-perplexity increases, suggesting the model becomes less confident in these reconstructed sequences (for the 650M-parameter ESM2 model)."
  },
  {
    "objectID": "index.html#discussion-and-conclusions",
    "href": "index.html#discussion-and-conclusions",
    "title": "Do protein language models understand evolution? Mixed evidence from ancestral sequences and ESM2 –",
    "section": "Discussion and conclusions",
    "text": "Discussion and conclusions\nOur analysis suggests that ESM2 models, particularly at larger scales, capture some aspects of evolutionary signal in a context-dependent and inconsistent manner. While it’s difficult to distinguish true phylogenetic understanding from overfitting to training sequences, we observe several intriguing patterns:\nLower pseudo-perplexity for ancestral sequences.\nAcross both gene families and species, ESM2 often assigns lower pseudo-perplexity scores to reconstructed ancestral sequences than to extant descendants. This pattern is especially pronounced for high-confidence reconstructions, even though these ancestral sequences weren’t in the training data. This behavior has been previously observed for other protein families (Kantroo et al. (2024))\nDiscrimination between ML and consensus ancestors.\nIn cases where reconstructions are well-supported, ESM2 prefers maximum likelihood ancestors over simple consensus sequences, suggesting sensitivity to subtle features of evolutionary plausibility beyond mere amino acid frequency. However, this preference weakens for ancient or low-confidence ancestors, likely reflecting poor reconstruction quality or increasing divergence from the training set distribution.\nModel size affects evolutionary patterns.\nWhile larger ESM2 models (650M and 3B parameters) show more nuanced relationships between reconstruction confidence and evolutionary age, smaller models show flatter distributions, indicating reduced sensitivity. This suggests that some of this ability to interpret evolutionary relationships may emerge only in larger models.\nWhile these findings are limited to two gene families and a specific ASR approach, they support that ESM2’s treatment of ancestral sequences isn’t random and may reflect partial capture of phylogenetic information. Still, the patchiness of the observed patterns cautions against strong claims. Further investigation is needed to determine whether large protein language models like ESM2 genuinely encode evolutionary relationships, and orthogonal approaches may be needed to more deeply interrogate this idea. (Ektefaie et al. (2025))"
  },
  {
    "objectID": "pages/SETUP.html",
    "href": "pages/SETUP.html",
    "title": "Setup",
    "section": "",
    "text": "This document details how to create a local copy of this pub’s codebase, setup your compute environment, and reproduce the pub itself. This will enable you to experiment with the analysis in the pub and, optionally, contribute revisions to it.\n\n\nThe codebase is hosted on GitHub and can be found here.\nTo obtain a local copy of this repo, you can either clone it directly or fork it to your own GitHub account, then clone your fork. If you aren’t sure what’s best, our suggestion is to clone directly unless you both (1) want to propose a revision for the publication and (2) are not an employee of Arcadia Science.\nTo clone:\ngit clone https://github.com/Arcadia-Science/2025-asr-plms.git\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe publication is rendered with Quarto. If you don’t have it installed (check with quarto --version), you can install it here.\n\n\nThis repository uses conda to manage the computational and build environment. If you don’t have it installed (check with conda --version), you can find operating system-specific instructions for installing miniconda here. After installing, run the following commands to create and activate the environment.\nconda env create -n 2025-asr-plms --file env.yml\nconda activate 2025-asr-plms\nNow, install any internal packages in the repository:\npip install -e .\nAnd finally, if you plan to submit a pull request, install the pre-commit hooks:\npre-commit install"
  },
  {
    "objectID": "pages/SETUP.html#obtain-local-copy",
    "href": "pages/SETUP.html#obtain-local-copy",
    "title": "Setup",
    "section": "",
    "text": "The codebase is hosted on GitHub and can be found here.\nTo obtain a local copy of this repo, you can either clone it directly or fork it to your own GitHub account, then clone your fork. If you aren’t sure what’s best, our suggestion is to clone directly unless you both (1) want to propose a revision for the publication and (2) are not an employee of Arcadia Science.\nTo clone:\ngit clone https://github.com/Arcadia-Science/2025-asr-plms.git"
  },
  {
    "objectID": "pages/SETUP.html#installation",
    "href": "pages/SETUP.html#installation",
    "title": "Setup",
    "section": "",
    "text": "Important\n\n\n\nThe publication is rendered with Quarto. If you don’t have it installed (check with quarto --version), you can install it here.\n\n\nThis repository uses conda to manage the computational and build environment. If you don’t have it installed (check with conda --version), you can find operating system-specific instructions for installing miniconda here. After installing, run the following commands to create and activate the environment.\nconda env create -n 2025-asr-plms --file env.yml\nconda activate 2025-asr-plms\nNow, install any internal packages in the repository:\npip install -e .\nAnd finally, if you plan to submit a pull request, install the pre-commit hooks:\npre-commit install"
  },
  {
    "objectID": "pages/SETUP.html#reproduce",
    "href": "pages/SETUP.html#reproduce",
    "title": "Setup",
    "section": "Reproduce",
    "text": "Reproduce\nThe best way to ensure you’ve correctly set up your code and compute environment is to reproduce this work. Fortunately, the analysis, and therefore the publication itself, can be reproduced with the following command:\nmake execute\n(Make sure you’re in the conda environment you created above)\nThis will execute and render the notebook index.ipynb, then build the publication site. To preview the site, use\nmake preview\nThis will open a local instance of the publication in your default browser."
  },
  {
    "objectID": "pages/SETUP.html#modify",
    "href": "pages/SETUP.html#modify",
    "title": "Setup",
    "section": "Modify",
    "text": "Modify\nTo modify or extend any analyses, open up index.ipynb with Jupyter or your favorite IDE. To preview changes as you modify the notebook, run make preview again and leave the command running. As you make changes to the notebook, the preview site will automatically reload."
  },
  {
    "objectID": "pages/SETUP.html#publish",
    "href": "pages/SETUP.html#publish",
    "title": "Setup",
    "section": "Publish",
    "text": "Publish\nIf you’ve improved the publication, consider contributing so we can update the hosted publication with your edits (big or small!). To get started, see our contributing guide."
  },
  {
    "objectID": "pages/CONTRIBUTING.html",
    "href": "pages/CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "We welcome improvements to this publication! If you’d like to improve or extend the publication, please submit a pull request. We’ll collaborate with you to incorporate your revisions. Alternatively, you’re welcome to leave a comment on the pub using Giscus.\n\nDid you spot any mistakes?\nDo you think an analysis is missing?\nDo you think the wording could be improved?\nDid you spot a typo or grammatical mistake?\n\nThese are just a few examples of revisions that we’d be happy to receive from you.\n\n\n\n\n\n\nNote\n\n\n\nTo learn about how we credit external collaborators, click here.\n\n\n\n\nIf you haven’t already, follow our setup guide to create a local copy of the code and compute environment.\n\n\n\nEdit index.ipynb to your liking.\n\n\n\nTo publish your revisions, we need you to open a pull request. And in order for us to merge your pull request, here’s what we’ll need from you in addition to your content changes.\nBegin with a clean branch (no uncommitted changes). Then run the notebook from the command line:\nmake execute\nThis command will update index.ipynb with the latest execution results.\nThen run make preview to see how the publication is rendering. Verify that your changes appear how you intend them to appear. If not, make the necessary changes and re-run make execute.\nOnce everything looks good, commit index.ipynb and all files in the _freeze/ directory.\nFinally, submit a pull request and we’ll work with you to merge your changes.\nOnce we approve and merge your pull request, we’ll publish a new version of the pub. We’ll notify you when this new version goes live at the hosted URL. Thanks for contributing!"
  },
  {
    "objectID": "pages/CONTRIBUTING.html#getting-started",
    "href": "pages/CONTRIBUTING.html#getting-started",
    "title": "Contributing",
    "section": "",
    "text": "If you haven’t already, follow our setup guide to create a local copy of the code and compute environment."
  },
  {
    "objectID": "pages/CONTRIBUTING.html#make-your-changes",
    "href": "pages/CONTRIBUTING.html#make-your-changes",
    "title": "Contributing",
    "section": "",
    "text": "Edit index.ipynb to your liking."
  },
  {
    "objectID": "pages/CONTRIBUTING.html#steps-before-publishing",
    "href": "pages/CONTRIBUTING.html#steps-before-publishing",
    "title": "Contributing",
    "section": "",
    "text": "To publish your revisions, we need you to open a pull request. And in order for us to merge your pull request, here’s what we’ll need from you in addition to your content changes.\nBegin with a clean branch (no uncommitted changes). Then run the notebook from the command line:\nmake execute\nThis command will update index.ipynb with the latest execution results.\nThen run make preview to see how the publication is rendering. Verify that your changes appear how you intend them to appear. If not, make the necessary changes and re-run make execute.\nOnce everything looks good, commit index.ipynb and all files in the _freeze/ directory.\nFinally, submit a pull request and we’ll work with you to merge your changes.\nOnce we approve and merge your pull request, we’ll publish a new version of the pub. We’ll notify you when this new version goes live at the hosted URL. Thanks for contributing!"
  },
  {
    "objectID": "pages/FAQ.html",
    "href": "pages/FAQ.html",
    "title": "FAQ",
    "section": "",
    "text": "This notebook publication uses a format we’re experimenting with that treats a scientist’s working computational analysis as the publication itself, dissolving the separation that exists between code and publication. Our hypothesis is that this lets us publish faster, promote early-stage work, and increase reproducibility. For details, see our commentary on notebook publications.\n\n\n\nThere is a comment section at the bottom of the pub, where you can read and contribute to any community discussion. Note that commenting requires a GitHub account and authorizing Giscus, a GitHub Discussions widget.\n\n\n\nAll the code for this publication and its analysis are hosted on GitHub at this URL. Any associated data is either hosted or linked to from this repository.\n\n\n\nReproducing this publication is as easy as issuing a few commands from the command line. Follow this setup guide to get started.\n\n\n\nWe welcome improvements to this publication! Please see our guide for contributing."
  },
  {
    "objectID": "pages/FAQ.html#what-is-this",
    "href": "pages/FAQ.html#what-is-this",
    "title": "FAQ",
    "section": "",
    "text": "This notebook publication uses a format we’re experimenting with that treats a scientist’s working computational analysis as the publication itself, dissolving the separation that exists between code and publication. Our hypothesis is that this lets us publish faster, promote early-stage work, and increase reproducibility. For details, see our commentary on notebook publications."
  },
  {
    "objectID": "pages/FAQ.html#how-can-i-comment",
    "href": "pages/FAQ.html#how-can-i-comment",
    "title": "FAQ",
    "section": "",
    "text": "There is a comment section at the bottom of the pub, where you can read and contribute to any community discussion. Note that commenting requires a GitHub account and authorizing Giscus, a GitHub Discussions widget."
  },
  {
    "objectID": "pages/FAQ.html#where-is-the-datacode",
    "href": "pages/FAQ.html#where-is-the-datacode",
    "title": "FAQ",
    "section": "",
    "text": "All the code for this publication and its analysis are hosted on GitHub at this URL. Any associated data is either hosted or linked to from this repository."
  },
  {
    "objectID": "pages/FAQ.html#how-can-i-reproduce-this",
    "href": "pages/FAQ.html#how-can-i-reproduce-this",
    "title": "FAQ",
    "section": "",
    "text": "Reproducing this publication is as easy as issuing a few commands from the command line. Follow this setup guide to get started."
  },
  {
    "objectID": "pages/FAQ.html#how-can-i-contribute",
    "href": "pages/FAQ.html#how-can-i-contribute",
    "title": "FAQ",
    "section": "",
    "text": "We welcome improvements to this publication! Please see our guide for contributing."
  },
  {
    "objectID": "ASR/ASR_notebook.html",
    "href": "ASR/ASR_notebook.html",
    "title": "Recode deflines to 10 character max",
    "section": "",
    "text": "import json\nimport os\nimport shutil\nimport subprocess\nfrom pathlib import Path\n\nimport ete3\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom Bio import AlignIO, Phylo, SeqIO\nfrom ete3 import Tree\nfrom pastml import acr\n# This cell is modified by papermill for CLI execution during runtime\ninput_fasta = \"placeholder\"\noutgroup_path = \"placeholder\"\ninput_fasta = Path(input_fasta)\noutgroup_path = Path(outgroup_path)\nrun_folder = Path(\"ADA1_ASR/outputs\")\nrun_folder.mkdir(exist_ok=True, parents=True)\n# Recode them to 10 char max (PAML is limited to phylip format with 10 char max)\nrecoded_input_fasta = run_folder / f\"{input_fasta.stem}_recoded.fa\"\nrecoding_dict_file = run_folder / \"recoding_dict.txt\"\n\ncounter = 0\nwith open(recoding_dict_file, \"w\") as dict_file:\n    with open(recoded_input_fasta, \"w\") as seq_file:\n        for record in SeqIO.parse(input_fasta, \"fasta\"):\n            seq_name = \"seq\" + str(counter)\n            seq_file.write(\"&gt;\" + seq_name + \"\\n\" + str(record.seq) + \"\\n\")\n            dict_file.write(seq_name + \"\\t\" + record.id + \"\\n\")\n            counter += 1"
  },
  {
    "objectID": "ASR/ASR_notebook.html#build-alignment-with-mafft",
    "href": "ASR/ASR_notebook.html#build-alignment-with-mafft",
    "title": "Recode deflines to 10 character max",
    "section": "Build alignment with MAFFT",
    "text": "Build alignment with MAFFT\n\nmafft_out = recoded_input_fasta.with_stem(recoded_input_fasta.stem + \"_mafft\")\n\nmafft_cmd = f\"mafft --localpair {recoded_input_fasta} &gt; {mafft_out}\"\n\ntry:\n    result = subprocess.run(mafft_cmd, shell=True, check=True, text=True, capture_output=True)\n    print(f\"Alignment file {mafft_out} generated\")\nexcept subprocess.CalledProcessError as e:\n    print(\"Error occurred during execution\")\n    print(e.stderr)\n\n# convert to Phylip sequential format for PAML\nmafft_phylip = mafft_out.with_suffix(\".ph\")\n\nalignment = AlignIO.read(mafft_out, \"fasta\")\nAlignIO.write(alignment, mafft_phylip, \"phylip-sequential\")"
  },
  {
    "objectID": "ASR/ASR_notebook.html#find-best-model-and-build-tree-with-iq-tree",
    "href": "ASR/ASR_notebook.html#find-best-model-and-build-tree-with-iq-tree",
    "title": "Recode deflines to 10 character max",
    "section": "Find Best Model and Build Tree with IQ Tree",
    "text": "Find Best Model and Build Tree with IQ Tree\n\niqtree_cmd = f\"iqtree2 -s {mafft_out} -m TESTONLY -nt AUTO -redo\"\n\ntry:\n    result = subprocess.run(iqtree_cmd, shell=True, check=True, text=True, capture_output=True)\nexcept subprocess.CalledProcessError as e:\n    print(e.stderr)\n\n\n# pull out best model from output files and list of models in order\n\nall_models = []\niqtree_output_path = mafft_out.with_name(f\"{mafft_out.name}.iqtree\")\nwith open(iqtree_output_path) as file:\n    flag = 0\n    for line in file:\n        if \"Best-fit model according to BIC\" in line:\n            model_name = line.rstrip().split(\":\")[1].replace(\" \", \"\")\n            print(f\"Best model: {model_name}\")\n            flag = 1\n        elif flag == 1:\n            all_models.append(line.split(\" \")[0])\n\n\n# write best model to separate file to prevent overwriting in treebuilding\nshutil.move(iqtree_output_path, mafft_out.with_name(f\"{mafft_out.name}.bestmodel\"))\n\n\n# build tree with best model\niqtree_cmd = f\"iqtree2 -s {mafft_out} -m {model_name} -nt AUTO -redo\"\nprint(iqtree_cmd)\ntry:\n    result = subprocess.run(iqtree_cmd, shell=True, check=True, text=True, capture_output=True)\n    print(f\"Tree file {mafft_out} generated\")\n\nexcept subprocess.CalledProcessError as e:\n    print(e.stderr)\n\niqtree_tree = mafft_out.with_name(f\"{mafft_out.name}.treefile\")"
  },
  {
    "objectID": "ASR/ASR_notebook.html#root-tree-with-known-outgroup",
    "href": "ASR/ASR_notebook.html#root-tree-with-known-outgroup",
    "title": "Recode deflines to 10 character max",
    "section": "Root tree with known outgroup",
    "text": "Root tree with known outgroup\n\n# root tree with known outgroups\noutgroup_names = [line.strip() for line in open(outgroup_path).readlines()]\n\n# get recoded names of outgroups\noutgroup_names_recoded = []\nwith open(recoding_dict_file) as file:\n    for line in file:\n        names = line.rstrip().split(\"\\t\")\n        if names[1] in outgroup_names:\n            outgroup_names_recoded.append(names[0])\n\ntree = Phylo.read(iqtree_tree, \"newick\")\noutgroup_clade = tree.common_ancestor(outgroup_names_recoded[1], outgroup_names_recoded[0])\ntree.root_with_outgroup(outgroup_clade)\n\nrooted_tree = iqtree_tree.with_name(iqtree_tree.stem.split(\".\")[0] + \"_rooted.txt\")\nPhylo.write(tree, rooted_tree, \"newick\")\n\nprint(f\"Rooted tree saved to {rooted_tree}\")"
  },
  {
    "objectID": "ASR/ASR_notebook.html#format-files-for-paml",
    "href": "ASR/ASR_notebook.html#format-files-for-paml",
    "title": "Recode deflines to 10 character max",
    "section": "Format files for PAML",
    "text": "Format files for PAML\n\n# get closest substitution matrix in paml to match best model from iqtree\n\nmodel_dict = {\n    \"cpREV\": \"cpREV64.dat\",\n    \"Dayhoff\": \"dayhoff.dat\",\n    \"DCMut\": \"dayhoff-dcmut.dat\",\n    \"JTTDCMut\": \"jones-dcmut.dat\",\n    \"JTT\": \"jones.dat\",\n    \"LG\": \"lg.dat\",\n    \"mtART\": \"mtArt.dat\",\n    \"mtMAM\": \"mtmam.dat\",\n    \"mtREV\": \"mtREV24.dat\",\n    \"mtZOA\": \"MtZoa.dat\",\n    \"WAG\": \"wag.dat\",\n}\n\nfor entry in all_models:\n    if entry.split(\"+\")[0] in model_dict:\n        paml_model = entry\n        print(\"best paml-compatible model: \", paml_model)\n        if \"G4\" in entry:\n            final_cats = 4\n        else:\n            final_cats = 1\n        print(\"nCatG: \", final_cats)\n        break\n\nfinal_model = model_dict[paml_model.split(\"+\")[0]]"
  },
  {
    "objectID": "ASR/ASR_notebook.html#reconstruct-ml-ancestors-with-paml",
    "href": "ASR/ASR_notebook.html#reconstruct-ml-ancestors-with-paml",
    "title": "Recode deflines to 10 character max",
    "section": "Reconstruct ML ancestors with PAML",
    "text": "Reconstruct ML ancestors with PAML\n\n# modify config file based on sample file\nsample_config_file = \"codeml_example.ctl\"\nnew_config_file = run_folder / \"codeml.ctl\"\n\nconda_env_path = os.environ.get(\"CONDA_PREFIX\")\n\nwith open(new_config_file, \"w\") as outfile:\n    with open(sample_config_file) as file:\n        for line in file:\n            if \"seqfile\" in line:\n                outfile.write(f\"seqfile = {mafft_phylip} \\n\")\n            elif \"treefile\" in line:\n                outfile.write(f\"treefile = {rooted_tree} \\n\")\n            elif \"aaRatefile\" in line:\n                outfile.write(f\"aaRatefile = {conda_env_path + '/dat/' + final_model} \\n\")\n            elif \"ncatG\" in line:\n                outfile.write(f\"ncatG = {final_cats} \\n\")\n\n            else:\n                outfile.write(line)\n\nprint(\n    f\"config file writted with aaRatefile {os.path.basename(final_model)} and nCatG = {final_cats}\"\n)\n\n\n# run codeml\n\ncodeml_cmd = f\"codeml {new_config_file}\"\n\n# check if subsitution rate file exists (paml will get stuck otherwise)\nwith open(new_config_file) as file:\n    for line in file:\n        if \"aaRatefile\" in line:\n            rate_file = line.rstrip().split(\"aaRatefile = \")[1]\n\n# run paml if rate file exists\nif not os.path.exists(rate_file):\n    print(f\"Error: Rate file '{rate_file}' does not exist.\")\nelse:\n    try:\n        result = subprocess.run(codeml_cmd, shell=True, check=True, text=True, capture_output=True)\n    except subprocess.CalledProcessError as e:\n        if \"error: end of tree file.\" not in e.stderr:  # ignore this error\n            print(e.stderr)\n\n\n# move output files to run folder\noutputs = [\"codeml_results.txt\", \"rst\", \"rst1\", \"rub\", \"rates\", \"lnf\"]\n\nfor entry in outputs:\n    shutil.move(entry, run_folder / entry)"
  },
  {
    "objectID": "ASR/ASR_notebook.html#parse-paml-output-files-to-get-ml-sequences-and-probabilities",
    "href": "ASR/ASR_notebook.html#parse-paml-output-files-to-get-ml-sequences-and-probabilities",
    "title": "Recode deflines to 10 character max",
    "section": "Parse PAML output files to get ML sequences and probabilities",
    "text": "Parse PAML output files to get ML sequences and probabilities\n\nGenerate ancestor trees in different formats\n\nancestor_cladogram = run_folder / \"ancestor_cladogram.txt\"\nancestor_recoded_cladogram = run_folder / \"ancestor_recoded_cladogram.txt\"\nancestor_tree = run_folder / \"ancestor_tree.txt\"\nancestor_recoded_tree = run_folder / \"ancestor_recoded_tree.txt\"\n\n# pull out ancestor tree string from rst file\ntree_string = \"\"\nflag = 0\nwith open(run_folder / \"rst\") as file:\n    for line in file:\n        if \"tree with node labels for Rod Page's TreeView\" in line:\n            flag = 1\n        elif \"are ancestral\" in line:\n            flag = 0\n        elif flag == 1:\n            tree_string = tree_string + line\n\n# remove codeml numbers from sequence names\nwith open(ancestor_recoded_cladogram, \"w\") as file:\n    file.write(tree_string)\n\nterminals = [x.name for x in Phylo.read(ancestor_recoded_cladogram, \"newick\").get_terminals()]\nfor entry in terminals:\n    tree_string = tree_string.replace(entry + \",\", entry.split(\"_\")[1] + \",\")\n    tree_string = tree_string.replace(entry + \")\", entry.split(\"_\")[1] + \")\")\n\n# remove codeml numbers from sequence names\nwith open(ancestor_recoded_cladogram, \"w\") as file:\n    file.write(tree_string)\n\n# recode ancestor cladogram to original names\nname_dict = dict(\n    zip(\n        [line.rstrip().split(\"\\t\")[0] for line in open(recoding_dict_file)],\n        [line.rstrip().split(\"\\t\")[1] for line in open(recoding_dict_file)],\n        strict=False,\n    )\n)\n\nfor entry in name_dict:\n    tree_string = tree_string.replace(entry + \",\", name_dict[entry] + \",\")\n    tree_string = tree_string.replace(entry + \")\", name_dict[entry] + \")\")\n\n# write to cladogram file\nwith open(ancestor_cladogram, \"w\") as outfile:\n    outfile.write(tree_string)\n\n\n# Transfer node labels to tree with branch lengths\ncladogram_tree = Tree(str(ancestor_cladogram), format=1)  # Format 1 preserves internal node names\nbranch_length_tree = Tree(str(rooted_tree), format=1)  # No node names, but correct topology\n\n# Extract internal node labels from cladogram\ncladogram_nodes = cladogram_tree.get_descendants(\"postorder\")\nbranch_nodes = branch_length_tree.get_descendants(\"postorder\")\n\n# Create a mapping of cladogram node labels to their topological positions\nnode_label_map = {}\nfor node in cladogram_nodes:\n    if node.name:  # Internal node labels\n        node_label_map[id(node)] = node.name\n\n# Assign labels to the branch-length tree, assuming same topology\nfor clad_node, branch_node in zip(cladogram_nodes, branch_nodes, strict=False):\n    if id(clad_node) in node_label_map:\n        branch_node.name = node_label_map[id(clad_node)]\n\n# Save the updated tree with labels\nbranch_length_tree.write(outfile=ancestor_tree, format=1)\n\n# REPEAT FOR RECODED TREE\n# Add node labels to original trees (orig and recoded both)\ncladogram_tree = Tree(str(ancestor_recoded_cladogram), format=1)  # Format 1 preserves node names\nbranch_length_tree = Tree(str(rooted_tree), format=1)  # No node names, but correct topology\n\n# Extract internal node labels from cladogram\ncladogram_nodes = cladogram_tree.get_descendants(\"postorder\")\nbranch_nodes = branch_length_tree.get_descendants(\"postorder\")\n\n# Create a mapping of cladogram node labels to their topological positions\nnode_label_map = {}\nfor node in cladogram_nodes:\n    if node.name:  # Internal node labels\n        node_label_map[id(node)] = node.name\n\n# Assign labels to the branch-length tree, assuming same topology\nfor clad_node, branch_node in zip(cladogram_nodes, branch_nodes, strict=False):\n    if id(clad_node) in node_label_map:\n        branch_node.name = node_label_map[id(clad_node)]\n\n# Save the updated tree with labels\nbranch_length_tree.write(outfile=ancestor_recoded_tree, format=1)\n\n\n\nMake files with ML Sequences and Posterior Probabilities (all nodes with gaps)\n\ncodeml_results = run_folder / \"rst\"\n\nflag = 0\nseqs_dict = {}\nprobs_dict = {}\nres_list = [\n    \"A\",\n    \"C\",\n    \"D\",\n    \"E\",\n    \"F\",\n    \"G\",\n    \"H\",\n    \"I\",\n    \"K\",\n    \"L\",\n    \"M\",\n    \"N\",\n    \"P\",\n    \"Q\",\n    \"R\",\n    \"S\",\n    \"T\",\n    \"V\",\n    \"W\",\n    \"Y\",\n]\n\nwith open(codeml_results) as file:\n    for line in file:\n        if \"Prob distribution at node\" in line and \" by site\" in line:\n            node = \"node\" + line.split(\"node \")[1].split(\",\")[0]\n            seqs_dict[node] = \"\"\n            probs_dict[node] = []\n            flag = 1\n        elif flag == 1 and \":\" in line:\n            all_probs = line.rstrip().split(\":\")[1].split(\" \")[1:]\n            letters = [x.split(\"(\")[0] for x in all_probs]\n            probs = [float(x.split(\"(\")[1].split(\")\")[0]) for x in all_probs]\n            support_dict = dict(zip(letters, probs, strict=False))\n            max_res = max(support_dict, key=support_dict.get)\n            seqs_dict[node] = seqs_dict[node] + max_res\n            probs_ordered = [support_dict[x] for x in res_list]\n            probs_dict[node].append(probs_ordered)\n\n        elif \"Prob of best state at each node, listed by site\" in line:\n            break\n\nml_seqs_with_gaps = run_folder / \"ML_ancestors_with_gaps.fa\"\n\nwith open(ml_seqs_with_gaps, \"w\") as file:\n    for entry in seqs_dict:\n        file.write(\"&gt;\" + entry + \"\\n\" + seqs_dict[entry] + \"\\n\")\n\npost_probs_file = run_folder / \"posterior_probabilities.json\"\n\nwith open(post_probs_file, \"w\") as file:\n    json.dump(probs_dict, file, indent=4)"
  },
  {
    "objectID": "ASR/ASR_notebook.html#identify-gap-positions-based-on-parsimony-using-downpass-algorithm-from-topiary",
    "href": "ASR/ASR_notebook.html#identify-gap-positions-based-on-parsimony-using-downpass-algorithm-from-topiary",
    "title": "Recode deflines to 10 character max",
    "section": "Identify gap positions based on parsimony using DOWNPASS algorithm from Topiary",
    "text": "Identify gap positions based on parsimony using DOWNPASS algorithm from Topiary\n\ndef read_alignment(file_path):\n    \"\"\"\n    Read the PHYLIP alignment file and return a gap matrix.\n    \"\"\"\n    alignment = AlignIO.read(file_path, \"phylip\")\n\n    # Initialize a list to store gap info\n    taxa_names = [record.id for record in alignment]\n    num_sites = alignment.get_alignment_length()\n\n    # Create a matrix for gaps (True = gap, False = no gap)\n    gap_matrix = np.zeros((len(taxa_names), num_sites), dtype=np.uint8)\n\n    for i, record in enumerate(alignment):\n        for j, char in enumerate(record.seq):\n            gap_matrix[i, j] = 1 if char == \"-\" else 0\n\n    # Convert the gap matrix into a pandas DataFrame\n    gap_df = pd.DataFrame(gap_matrix, columns=[f\"g{i}\" for i in range(num_sites)], index=taxa_names)\n\n    return gap_df, taxa_names\n\n\ndef parse_tree(tree_file):\n    \"\"\"\n    Parse the tree and return the tree object.\n    \"\"\"\n    tree = ete3.Tree(tree_file, format=1)\n    return tree\n\n\ndef infer_ancestral_gaps(alignment_file, tree_file, prediction_method=\"DOWNPASS\"):\n    \"\"\"\n    Infer gaps at ancestral nodes using the acr function from pastml.\n    \"\"\"\n    # Step 2: Read the PHYLIP alignment file\n    gap_df, leaf_names = read_alignment(alignment_file)\n\n    # Step 3: Parse the tree file\n    tree = parse_tree(str(tree_file))\n\n    # Step 4: Run the gap reconstruction using the DOWNPASS algorithm\n    acr.acr(tree, gap_df, prediction_method=prediction_method)\n\n    # Step 5: Create a dictionary for gaps in ancestral nodes\n    gap_anc_dict = {}\n    for node in tree.traverse(\"preorder\"):\n        if node.name in leaf_names:\n            continue  # Skip leaf nodes\n\n        gap_anc_dict[node.name] = []\n\n        # Collect gap information for each ancestral node\n        for col in gap_df.columns:\n            state = node.__dict__.get(col, None)\n\n            if isinstance(state, set):\n                if len(state) == 1:\n                    state = True if 1 in state else False\n                else:\n                    state = None\n            gap_anc_dict[node.name].append(state)\n\n    return gap_anc_dict\n\n\nalignment_file = mafft_phylip\ntree_file = ancestor_recoded_tree\n\ngap_anc_dict = infer_ancestral_gaps(alignment_file, tree_file, prediction_method=\"DOWNPASS\")\n\n# write gaps to json\ngaps_file = run_folder / \"gap_positions.json\"\nwith open(gaps_file, \"w\") as file:\n    json.dump(gap_anc_dict, file, indent=4)\n\n\nUse gap positions to write ungapped ML sequences to output file\n\nml_seqs_no_gaps = run_folder / \"ML_ancestors.fa\"\n\nwith open(ml_seqs_no_gaps, \"w\") as file:\n    for record in SeqIO.parse(ml_seqs_with_gaps, \"fasta\"):\n        node_num = record.id.split(\"node\")[1]\n        if node_num not in gap_anc_dict:\n            # no gaps inferred for deepest node (shouldnt reconstruct this anyway)\n            print(\"no gaps inferred for node \", node_num, \"(root node)\")\n        else:\n            full_seq = list(str(record.seq))\n            trimmed_seq = (\"\").join(\n                [x for i, x in enumerate(full_seq) if not gap_anc_dict[node_num][i]]\n            )\n            file.write(f\"&gt;node{node_num}\\n{trimmed_seq}\\n\")\n\n\n\nUse gap positions to write ungapped probabilities to output file\n\npost_probs_no_gaps = run_folder / \"posterior_probabilities_no_gaps.json\"\n\nwith open(post_probs_file) as f:\n    probs_dict = json.load(f)\n\n# mask positions with gaps\nprobs_dict_no_gaps = {}\n\nfor entry in probs_dict:\n    node_num = entry.split(\"node\")[1]\n    if node_num not in gap_anc_dict:\n        print(\"no gaps inferred for node \", node_num, \" (root node)\")\n    else:\n        full_matrix_probs = probs_dict[entry]\n        matrix_masked = [\n            x for i, x in enumerate(full_matrix_probs) if not gap_anc_dict[node_num][i]\n        ]\n        probs_dict_no_gaps[entry] = matrix_masked\n\n\nwith open(post_probs_no_gaps, \"w\") as file:\n    json.dump(probs_dict_no_gaps, file, indent=4)"
  },
  {
    "objectID": "ASR/ASR_notebook.html#visualize-tree-with-ancestral-nodes-labeled-recommend-figtree-for-easier-viewing",
    "href": "ASR/ASR_notebook.html#visualize-tree-with-ancestral-nodes-labeled-recommend-figtree-for-easier-viewing",
    "title": "Recode deflines to 10 character max",
    "section": "Visualize tree with ancestral nodes labeled (recommend FigTree for easier viewing)",
    "text": "Visualize tree with ancestral nodes labeled (recommend FigTree for easier viewing)\n\ntree = Phylo.read(ancestor_tree, \"newick\")\n\nfig = plt.figure(figsize=(15, 60))  # Adjust size (width, height)\nax = fig.add_subplot(1, 1, 1)\n\n# Customize and render the tree\nPhylo.draw(\n    tree,\n    axes=ax,\n    label_colors={\"orange\": \"orange\"},  # Specify colors for labels\n    do_show=False,  # Prevent automatic display\n)\n\n# Manually highlight nodes by drawing them in orange\nfor clade in tree.find_clades():\n    if hasattr(clade, \"color\") and clade.color == \"orange\":\n        ax.text(\n            clade.branch_length,  # X-coordinate\n            tree.depths()[clade],  # Y-coordinate\n            clade.name,  # Node label\n            color=\"orange\",\n            fontsize=8,\n        )\n\n# Show the plot\nplt.show()"
  }
]